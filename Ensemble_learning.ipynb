{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/IUw1wmUPn7T2xwrCgLg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaykumar-coder/searce/blob/main/Ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPAFABC1jTHU"
      },
      "source": [
        "Max Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RGAbQSSh-F7"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier()\n",
        "model2 = KNeighborsClassifier()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(x_train,y_train)\n",
        "model2.fit(x_train,y_train)\n",
        "model3.fit(x_train,y_train)\n",
        "\n",
        "pred1=model1.predict(x_test)\n",
        "pred2=model2.predict(x_test)\n",
        "pred3=model3.predict(x_test)\n",
        "\n",
        "final_pred = np.array([])\n",
        "for i in range(0,len(x_test)):\n",
        "    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOpUDo1ijfKJ"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
        "model.fit(x_train,y_train)\n",
        "model.score(x_test,y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6eljJVEkQKw"
      },
      "source": [
        "Averaging and weighted averaging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCQDeKiyjf5r"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier()\n",
        "model2 = KNeighborsClassifier()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(x_train,y_train)\n",
        "model2.fit(x_train,y_train)\n",
        "model3.fit(x_train,y_train)\n",
        "\n",
        "pred1=model1.predict_proba(x_test)\n",
        "pred2=model2.predict_proba(x_test)\n",
        "pred3=model3.predict_proba(x_test)\n",
        "\n",
        "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)\n",
        "\n",
        "finalpred=(pred1+pred2+pred3)/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l0TKtX9mr7X"
      },
      "source": [
        "Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbIkZpxuncbj"
      },
      "source": [
        "We first define a function to make predictions on n-folds of train and test dataset. This function returns the predictions for train and test for each model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K93izAf1kVti"
      },
      "source": [
        "def Stacking(model,train,y,test,n_fold):\n",
        "   folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
        "   test_pred=np.empty((test.shape[0],1),float)\n",
        "   train_pred=np.empty((0,1),float)\n",
        "   for train_indices,val_indices in folds.split(train,y.values):\n",
        "      x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
        "      y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
        "\n",
        "      model.fit(X=x_train,y=y_train)\n",
        "      train_pred=np.append(train_pred,model.predict(x_val))\n",
        "      test_pred=np.append(test_pred,model.predict(test))\n",
        "    return test_pred.reshape(-1,1),train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS9FUhYWnnoC"
      },
      "source": [
        "Now we’ll create two base models – decision tree and knn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTQ6M0bwnkEx"
      },
      "source": [
        "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred1=pd.DataFrame(train_pred1)\n",
        "test_pred1=pd.DataFrame(test_pred1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHS2F9-DnkZ-"
      },
      "source": [
        "model2 = KNeighborsClassifier()\n",
        "\n",
        "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
        "\n",
        "train_pred2=pd.DataFrame(train_pred2)\n",
        "test_pred2=pd.DataFrame(test_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du0SwFgin7_q"
      },
      "source": [
        "Create a third model, logistic regression, on the predictions of the decision tree and knn models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhlTEdnqn4Lp"
      },
      "source": [
        "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
        "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
        "\n",
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(df,y_train)\n",
        "model.score(df_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpMaj6PurJ2U"
      },
      "source": [
        "Algorithms based on Bagging and Boosting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oujeTtuSs6Fu"
      },
      "source": [
        "Bagging meta-estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdRJJ_B5rT8L"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import tree\n",
        "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6O4iDBxteok"
      },
      "source": [
        "Ada Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoTSwQdetnHl"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model = AdaBoostClassifier(random_state=1)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_gMwbhgu4ux"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXlPkfjtql9"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model= GradientBoostingRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3545BSGv-IX"
      },
      "source": [
        "XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrdrcR54wYFX"
      },
      "source": [
        "import xgboost as xgb\n",
        "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}